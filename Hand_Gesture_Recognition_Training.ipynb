{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Hand_Gesture_Recognition_Training",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "qmpsN9Cjc2Jk"
      },
      "source": [
        "#run this file on google colab\n",
        "#change hardware accelerator to GPU to reduce computation(model training time)\n",
        "#steps to change hardware accelerator \n",
        "#On taskbar, Runtime -> Change runtime type -> Hardware accelerator(dropdown) -> GPU -> Save\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "glIY56M82UYU"
      },
      "source": [
        "cd drive/MyDrive/Gestures"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IDCsT2tbc-ct"
      },
      "source": [
        "#importing libraries\n",
        "import os \n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils.np_utils import to_categorical\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YWWRSDQbeo5d"
      },
      "source": [
        "#selecting gestures for the model\n",
        "images = []\n",
        "gesture_names = []\n",
        "gesture_counts = []\n",
        "\n",
        "\n",
        "while(True):\n",
        "  folder_name = input(\"ENTER GESTURE FOLDER NAME : \")\n",
        "  if folder_name == 'exit':\n",
        "    break\n",
        "\n",
        "  gesture_name = input(\"ENTER GESTURE NAME : \")\n",
        "  gesture_names.append(gesture_name)\n",
        "\n",
        "  gesture_count = int(input(\"Number of \"+gesture_name + \" : \"))\n",
        "  gesture_counts.append(gesture_count)\n",
        "\n",
        "  image_count = 0\n",
        "  \n",
        "  for i in os.listdir('./'+folder_name):\n",
        "    image = cv2.imread(folder_name + '/' + i , 0)\n",
        "    images.append(image)\n",
        "    print(image_count , i)\n",
        "    image_count += 1\n",
        "\n",
        "    if image_count == gesture_count:\n",
        "      break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D8xNj9gLkBSj"
      },
      "source": [
        "x = np.array(images)\n",
        "x = x.reshape(x.shape[0],180,180,1)\n",
        "\n",
        "gesture_Y = []\n",
        "count_y = 0\n",
        "for i in range(len(gesture_names)):\n",
        "  for i in range(gesture_counts[count_y]):\n",
        "    gesture_Y.append(count_y)\n",
        "  count_y += 1 \n",
        "\n",
        "y = np.array(gesture_Y)\n",
        "y = to_categorical(y)\n",
        "\n",
        "x_train , x_test , y_train , y_test = train_test_split(x,y,test_size = 0.25)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jekmm7VtNbXp"
      },
      "source": [
        "def train_model(epochs,batch_size,activation,optimizer,output_count):\n",
        "\n",
        "  batch_size = batch_size\n",
        "  epochs = epochs\n",
        "  \n",
        "  model = Sequential()\n",
        "  model.add(Conv2D(32, kernel_size=(3, 3),activation=activation,input_shape=(180,180,1)))\n",
        "  model.add(Conv2D(64, (3, 3), activation=activation))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  model.add(Dropout(0.25))\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(128, activation=activation))\n",
        "  model.add(Dropout(0.5))\n",
        "  model.add(Dense(output_count, activation='softmax'))\n",
        "\n",
        "  model.compile(loss=keras.losses.categorical_crossentropy,optimizer=optimizer,metrics=['accuracy'])\n",
        "  model_re = model.fit(x_train, y_train,batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(x_test, y_test))\n",
        "\n",
        "  return model_re.history['accuracy'][-1],model_re.history['loss'][-1],model_re.history['val_accuracy'][-1],model_re.history['val_loss'][-1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uU56xrlYTg4R"
      },
      "source": [
        "#model performance of various combination\n",
        "optimizers = ['Adadelta','Adagrad','Adam','SGD']\n",
        "activation = ['relu','sigmoid','tanh','linear']\n",
        "\n",
        "total = []\n",
        "for opt in optimizers:\n",
        "  for act in activation:\n",
        "    row = []\n",
        "    row.append(opt)\n",
        "    row.append(act)\n",
        "    out = train_model(5,25,act,opt,3)\n",
        "    for res in out:\n",
        "      row.append(res)\n",
        "    total.append(row)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nv-3zTx0KNBx"
      },
      "source": [
        "#best model\n",
        "train_model(5,25,'relu','Adagrad',3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L1x9Ni0SThUF"
      },
      "source": [
        "#downloading model\n",
        "from keras.model import load_model\n",
        "model.save(\"25al_gestures.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}